{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage.segmentation import watershed, felzenszwalb\n",
    "from skimage.filters import sobel\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import rank\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import disk\n",
    "import sklearn.metrics\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = os.getcwd().replace('Code','Datasets')\n",
    "y_train_path = Path(datasets_dir + '\\\\y_train.csv')\n",
    "x_train_path = Path(datasets_dir + '\\\\X_train.zip')\n",
    "x_test_path = Path(datasets_dir + '\\\\X_test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "with zipfile.ZipFile(x_train_path, 'r') as ziptrain:\n",
    "    for info in ziptrain.infolist():\n",
    "        zip_img = ziptrain.open(info.filename)\n",
    "        cv_img = cv2.imdecode(np.frombuffer(zip_img.read(), dtype=np.uint8),\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "        train_list.append(cv_img)\n",
    "\n",
    "with zipfile.ZipFile(x_train_path, 'r') as ziptest:\n",
    "    for info in ziptest.infolist():\n",
    "        zip_img = ziptest.open(info.filename)\n",
    "        cv_img = cv2.imdecode(np.frombuffer(zip_img.read(), dtype=np.uint8),\n",
    "                              cv2.IMREAD_GRAYSCALE)\n",
    "        test_list.append(cv_img)        \n",
    "\n",
    "X_train = np.stack(train_list, axis=0)\n",
    "X_test = np.stack(test_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(y_train_path, index_col=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Model : W-Net architecture\n",
    "see this article : https://arxiv.org/pdf/1711.08506.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UEnc(nn.Module):\n",
    "\n",
    "    def __init__(self, in_filters: int, out_filters: int):\n",
    "\n",
    "        super(UEnc, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, stride=2)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_filters)\n",
    "        \n",
    "        conv1 = nn.Conv2d(in_filters, 64, kernel_size = 3)\n",
    "        conv2 = nn.Conv2d(in_filters, 64, kernel_size = 3)\n",
    "        maxpool1 = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        \n",
    "        \n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class UDec(nn.Module):\n",
    "    \"\"\"Decoder part of the model\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int, output_shape: int):\n",
    "        \"\"\"\n",
    "        :input_shape: int, shape of the input data\n",
    "        :output_shape: int, shape of the output data\n",
    "        \"\"\"\n",
    "        super(UDec, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Pushes a set of inputs (x) through the network.\n",
    "        :param x: Input values\n",
    "        :return: Module outputs\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "class WNet(nn.Module):\n",
    "    \"\"\"WNet model, with Encoder and Decoder\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \n",
    "        super(WNet, self).__init__()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "15fd02e5c878be06348de4aa47e758028f61ec77ef5ce2a754b2cbd26a6e5956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
